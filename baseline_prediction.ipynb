{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11826348,"sourceType":"datasetVersion","datasetId":7429202},{"sourceId":11843352,"sourceType":"datasetVersion","datasetId":7441121}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"curated_path = \"/kaggle/input/curated-data-abo/finl/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T02:51:40.498754Z","iopub.execute_input":"2025-05-16T02:51:40.498976Z","iopub.status.idle":"2025-05-16T02:51:40.507269Z","shell.execute_reply.started":"2025-05-16T02:51:40.49895Z","shell.execute_reply":"2025-05-16T02:51:40.506472Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install transformers torch pandas scikit-learn nltk","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom PIL import Image\nfrom transformers import Blip2Processor, Blip2ForConditionalGeneration\nimport re\nimport os\nfrom tqdm import tqdm\n\n# ========== Load BLIP-2 Model ==========\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprocessor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\", use_fast=True)\nmodel = Blip2ForConditionalGeneration.from_pretrained(\n    \"Salesforce/blip2-opt-2.7b\",\n    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n)\nmodel.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nvqapath = \"/kaggle/input/vqa23left/vqa23.csv\"\ndf = pd.read_csv(vqapath)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T17:52:34.911681Z","iopub.execute_input":"2025-05-15T17:52:34.912055Z","iopub.status.idle":"2025-05-15T17:52:35.157648Z","shell.execute_reply.started":"2025-05-15T17:52:34.912033Z","shell.execute_reply":"2025-05-15T17:52:35.156924Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T17:56:30.889845Z","iopub.execute_input":"2025-05-15T17:56:30.890214Z","iopub.status.idle":"2025-05-15T17:56:30.949791Z","shell.execute_reply.started":"2025-05-15T17:56:30.890189Z","shell.execute_reply":"2025-05-15T17:56:30.948991Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BATCH_SIZE = 32\nSAVE_EVERY = 32  # Save every N examples\nSAVE_PATH = \"qa_predictions_with_eval.csv\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T17:53:57.53148Z","iopub.execute_input":"2025-05-15T17:53:57.531797Z","iopub.status.idle":"2025-05-15T17:53:57.536121Z","shell.execute_reply.started":"2025-05-15T17:53:57.531774Z","shell.execute_reply":"2025-05-15T17:53:57.535233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if os.path.exists(SAVE_PATH):\n    result_df = pd.read_csv(SAVE_PATH)\n    start_idx = len(result_df)\n    print(f\"üîÅ Resuming from index {start_idx}\")\nelse:\n    result_df = pd.DataFrame(columns=df.columns.tolist() + ['predicted_answer', 'exact_match', 'f1_score'])\n    start_idx = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T17:54:00.285306Z","iopub.execute_input":"2025-05-15T17:54:00.285625Z","iopub.status.idle":"2025-05-15T17:54:00.297992Z","shell.execute_reply.started":"2025-05-15T17:54:00.285604Z","shell.execute_reply":"2025-05-15T17:54:00.297218Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def normalize_number_words(text):\n    num_map = {\n        \"zero\": \"0\", \"one\": \"1\", \"two\": \"2\", \"three\": \"3\", \"four\": \"4\",\n        \"five\": \"5\", \"six\": \"6\", \"seven\": \"7\", \"eight\": \"8\", \"nine\": \"9\",\n        \"ten\": \"10\"\n    }\n    words = text.lower().split()\n    converted = [num_map.get(word, word) for word in words]\n    return \" \".join(converted)\n\ndef normalize_text(text):\n    text = normalize_number_words(text)\n    text = text.lower()\n    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n    return text.strip()\n\ndef compute_f1(pred, truth):\n    pred_tokens = pred.split()\n    truth_tokens = truth.split()\n    common = set(pred_tokens) & set(truth_tokens)\n    if not common:\n        return 0.0\n    precision = len(common) / len(pred_tokens)\n    recall = len(common) / len(truth_tokens)\n    return 2 * (precision * recall) / (precision + recall)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport re\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm import tqdm\n\n# Config\nimage_folder = \"/kaggle/input/curated-data-abo/finl\"\nBATCH_SIZE = 128  # Adjust based on GPU\nSAVE_PATH = \"result1.csv\"\nstart_idx = 0\n\n# Initialize results\nall_results = []\n\nfor batch_start in tqdm(range(start_idx, len(df), BATCH_SIZE)):\n    batch_end = min(batch_start + BATCH_SIZE, len(df))\n    batch = df.iloc[batch_start:batch_end]\n\n    batch_results = []\n\n    for idx, row in batch.iterrows():\n        image_path = os.path.join(image_folder, row['image_path'])\n        question = str(row['question'])\n        gt_answer = str(row['answer'])\n\n        if not os.path.exists(image_path):\n            pred_answer = \"image_not_found\"\n            em = 0\n            f1 = 0.0\n        else:\n            try:\n                image = Image.open(image_path).convert(\"RGB\")\n                prompt = f\"Question: {question} Answer:\"\n                inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(device)\n\n                output = model.generate(**inputs, max_new_tokens=20, num_beams=5, early_stopping=True)\n                full_output = processor.decode(output[0], skip_special_tokens=True).strip()\n\n                # Extract answer\n                answer_only = re.sub(r\"(?i)question:.*?answer: ?\", \"\", full_output).strip()\n                answer_only = answer_only.split(\",\")[0].split(\".\")[0]\n                pred_answer = answer_only.strip().split()[0] if answer_only.strip() else \"unknown\"\n\n                # Normalize and score\n                pred_norm = normalize_text(pred_answer)\n                gt_norm = normalize_text(gt_answer)\n                em = int(pred_norm == gt_norm)\n                f1 = compute_f1(pred_norm, gt_norm)\n\n            except Exception as e:\n                print(f\"‚ùå Error at index {idx}: {e}\")\n                pred_answer = \"error\"\n                em = 0\n                f1 = 0.0\n\n        batch_results.append({\n            \"image_path\": row['image_path'],\n            \"question\": question,\n            \"answer\": gt_answer,\n            \"predicted_answer\": pred_answer,\n            \"exact_match\": em,\n            \"f1_score\": f1\n        })\n\n    all_results.extend(batch_results)\n\n    # Save to disk every batch\n    pd.DataFrame(all_results).to_csv(SAVE_PATH, index=False)\n    print(f\"üíæ Saved up to index {batch_end}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-05-15T17:57:40.022831Z","iopub.execute_input":"2025-05-15T17:57:40.023639Z"},"trusted":true},"outputs":[],"execution_count":null}]}